Model name,Use case,Model description,Owner,Version,Max allowed error rate for pipeline test,Settings for pipeline variables,Memory footprint,Training epochs,Training batch size,Training GPU,Intended users,Intended use cases,Out-of-scope use cases,Metrics,Evaluation Data,Training Data,Ethical Considerations,References
sid-minibert-20211021.onnx,sensitive-information-detection,"This model is a transformer-based sequence classifier (mini-bert) trained to detect sensitive data in unencrypted text. The ten categories of sensitive information include- address, bank account, credit card number, email address, government id number, full name, password, phone number, secret keys, and user names.",Rachel Allen,0.2.0,4%,for tokenizer: hash-file=bert-base-uncased max-length=256 stride=64 do-lower=TRUE do-truncation=FALSE,43MB,1,32,V100,cyber security and IT professionals,To detect leaked sensitive information from raw L7 payload data,This model version is designed for english language text data. It may not perform well on other languages.,F1=0.96,200k synthetic dataset with balanced classes for all 10 sensitive data labels, 2 million synethic pcap payloads generated using the faker repo to mimic sensitive and benign data found in nested jsons from web APIs and environmental variables,N/A,"Well-Read Students Learn Better: On the Importance of Pre-training Compact Models, 2019,  arXiv:1908.08962v2"
phishing-bert-20211006.onnx,phishing-email-detection,"This use case is currently implemeted to differentiate between phishing and non-phishing emails. The models for this use case are NLP models, specifically transformer-based models with attention (e.g., BERT).",Gorkem Batmaz,0.1.0,0.10%,for tokenizer: hash-file=bert-base-uncased max-length=128 stride=64 do-lower=TRUE do-truncation=FALSE,417MB,3,32,V100,cyber security and IT professionals,To detect phishing emails,This model version is designed for english language text data. It may not perform well on other languages.,F1=0.984,4946 labelled emails from three public datasets,19783 labelled emails from three public datasets,N/A,"Radev, D. (2008), CLAIR collection of fraud email, ACL Data and Code Repository, ADCR2008T001, http://aclweb.org/aclwiki
https://www.kaggle.com/rtatman/fraudulent-email-corpus *
https://www.cs.cmu.edu/~./enron/
https://spamassassin.apache.org/old/publiccorpus/readme.html
https://github.com/huggingface/transformers/tree/master/examples#
https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/
https://github.com/ThilinaRajapakse/pytorch-transformers-classification
https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
abp-nvsmi-xgb-20210310.bst,anomalous-behavior-profiling,"This use case is currently implemeted to differentiate between crypto mining / GPU malware and other GPU-based workflows (e.g., ML/DL training). The model is a XGBoost model.",Gorkem Batmaz,0.1.1,TBD,N/A,3KB,5,N/,V100,cyber security and IT professionals,To detect crypto mining,,Accuracy=1,248 labelled nv-smi logs,994 labelled nv-smi logs,N/A,"https://docs.rapids.ai/api/cuml/stable/
https://medium.com/rapids-ai/rapids-forest-inference-library-prediction-at-100-million-rows-per-second-19558890bc35
https://developer.nvidia.com/nvidia-system-management-interface
https://developer.nvidia.com/morpheus-cybersecurity
https://github.com/rapidsai/clx/blob/branch-0.20/examples/forest_inference/xgboost_training.ipynb"
hinsage_model.pt and xgb-model.pt,Fraud detection using GNN,"This use case a graph neural network based fraud detecter in transaction data 
.It uses a bipartite heteregenous graph representation as input for GraphSAGE for feature learning and XGBoost as a classifier.", Tad Zemicheal,0.1.1,TBD,N/A,756KB,25, 5 ,V100,cyber security and IT professionals,To detect fraud in transaction data,4%,AUC=0.96,265 labelled credit card transaction, 753 labelled credit card transaction data, N/A,"
https://stellargraph.readthedocs.io/en/stable/hinsage.html?highlight=hinsage,
https://github.com/rapidsai/clx/blob/branch-0.20/examples/forest_inference/xgboost_training.ipynb"
hammah-user123-20211017-dill.pkl,hammah,This use case is currently implemeted to detect changes in users' behavior that incate a change from a human to a machines or a machine to a human. The model is an ensemble of an autoencoder and fast fourier transform reconstruction.,Gorkem Batmaz,0.1,TBD,N/A,2.62MB,25,256,V100,cyber security and IT professionalsTo detect anomalies,The Autoencoder part needs retraining for different use cases or log types,,F1=1,847 rows of cloudtrail logs,3387 rows of cloudtrail logs,N/A,https://github.com/AlliedToasters/dfencoder/blob/master/dfencoder/autoencoder.py https://github.com/rapidsai/clx/blob/branch-22.04/notebooks/anomaly_detection/FFT_Outlier_Detection.ipynb Rasheed Peng Alhajj Rokne Jon: Fourier Transform Based Spatial Outlier Mining 2009
